<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Compilers | With Pith]]></title>
  <link href="http://ethanp.github.io/blog/categories/compilers/atom.xml" rel="self"/>
  <link href="http://ethanp.github.io/"/>
  <updated>2016-04-09T14:04:56-07:00</updated>
  <id>http://ethanp.github.io/</id>
  <author>
    <name><![CDATA[Ethan Petuchowski]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[First Glimpse of Compilers]]></title>
    <link href="http://ethanp.github.io/blog/2015/12/26/first-glimpse-of-compilers/"/>
    <updated>2015-12-26T22:49:00-08:00</updated>
    <id>http://ethanp.github.io/blog/2015/12/26/first-glimpse-of-compilers</id>
    <content type="html"><![CDATA[<p>I am close to two chapters into &ldquo;Compilers&rdquo; (a.k.a. &ldquo;The Dragon Book&rdquo;), by Aho,
Lam, Sethi, and Ullman. It is an exciting topic to learn about.</p>

<p>The most fundamental thing I have learned so far is the overall pipeline for
understanding the modular components forming the way a compiler is typically
constructed. It goes</p>

<ol>
<li>Lexical analyzer</li>
<li>Syntax analyzer</li>
<li>Semantic analyzer</li>
<li>Intermediate code generator</li>
<li><em>Machine-independent code optimizer</em> (optional)</li>
<li>Code generator</li>
<li><em>Machine-dependent code optimizer</em> (optional)</li>
</ol>


<p>The input to the compiler pipeline is a &ldquo;character stream&rdquo; of the program.
However I don&rsquo;t recall the book ever dealing with specifications of that
stream, except that it supports a generic <code>getchar()</code> operation. I can
understand that if the entire source consists of one file, you just read
character-by-character from the file into the compiler. Maybe the language
designer decides how multiple-file projects are to be read by the compiler,
i.e. it is beyond the scope of this book; or maybe they&rsquo;ll go more in-depth on
this later-on.</p>

<h3>The Lexical Analyzer</h3>

<p>The character stream is read into first component in the compilation pipeline:
the <strong>lexical analyzer</strong>, which maps the <em>character stream</em> into a <em>&ldquo;token&rdquo;
stream</em>. It seems like a <strong>token</strong> knows its <em>tag</em>, and its <em>value</em>. The
<strong>tag</strong> is basically the <em>type</em> of this token in the eyes of the compiler.
Possible tags in their example include <code>NUM</code>, <code>ID</code>, <code>[keyword]</code>s, and I added
<code>COMMENT</code> as part of an exercise. The <strong>value</strong> for a token might be the
literal <em>value</em> of a literal; or it might be the name of a variable. More about
that below.</p>

<h4>Symbol Tables</h4>

<p>In addition to creating the token stream, the lexical analyzer builds the
<em>symbol table</em>. It seems to that the <strong>symbol table</strong> maps names to places in
memory. A symbol table also &lsquo;by default&rsquo; implements the language&rsquo;s preferred
form of <em>block scoping</em>. Upon entering a new scope, a new symbol table is
created that points to its &ldquo;parent&rdquo;, the one it is nested inside of. If a
variable is <em>declared</em>, it is added to the symbol table to this scope. Later,
when a variable is <em>referenced</em> (i.e. init&rsquo;d, read, or updated), we will
consult the table for the current innermost scope. If the variable&rsquo;s data is
not found there, we will continue to check ancestors until we find it.</p>
]]></content>
  </entry>
  
</feed>
