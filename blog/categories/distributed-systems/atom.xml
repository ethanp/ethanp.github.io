<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Distributed Systems | With Pith]]></title>
  <link href="http://ethanp.github.io/blog/categories/distributed-systems/atom.xml" rel="self"/>
  <link href="http://ethanp.github.io/"/>
  <updated>2015-09-11T22:52:02-05:00</updated>
  <id>http://ethanp.github.io/</id>
  <author>
    <name><![CDATA[Ethan Petuchowski]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Summary of 'the Log']]></title>
    <link href="http://ethanp.github.io/blog/2015/05/29/summary-of-the-log/"/>
    <updated>2015-05-29T22:57:16-05:00</updated>
    <id>http://ethanp.github.io/blog/2015/05/29/summary-of-the-log</id>
    <content type="html"><![CDATA[<p>I read a great article by Jay Kreps, one of the dudes who brought you Apache
Kafka. The article is called <a href="http://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying"><strong>The Log</strong>: What every software engineer should know about real-time data&rsquo;s unifying abstraction</a>. The
article took me a few hours of mildly challenging reading, so I figure you can
spend a few minutes reading my summary and decide more clearly whether you want
to put in the investment of his explanation.</p>

<p>First, he describes the following concept: Let&rsquo;s define a <strong>log</strong> as a <em>total
order</em> of functions called and the parameters passed to each of those function-
calls. Let&rsquo;s define a <em>&ldquo;commit log&rdquo;</em> as a <em>log</em> of edits of the contents of a
database. Kreps notes that we can use a commmit log to build the state of a
database at any point in history. This is like <code>git</code>; as we patch in each
commit, we obtain the state of the repo at each time. If we feed the same log
to the same program on multiple machines in a cluster, (assuming none of the
functions called are <em>non- deterministic</em> and machines behave as we expect), we
will certainly have the same state on each machine after they have each
executed the log. This would be desireable perhaps to provide a &ldquo;reliable&rdquo;
<em>service</em> for which there are more reads than writes, and more reads than can
be handled by one node; then we can ensure any node is OK to read from by
having all nodes play functions as prescribed by the log.</p>

<p>Then, he describes the following situation: getting every part of a tech-
company&rsquo;s data to every service that needs it is very complicated. In the worst
and most naive case it would be <em>N<sup>2</sup></em> because each of <em>N</em> places would be sending
data to each of <em>N</em> places. That&rsquo;s a lot of network bandwidth, and complexity,
and data formats to understand, and places for things to screw up. So Kreps
suggests</p>

<!-- more -->


<p>just having all data producers standardize a framework for formatting
the data they produce, then just have all producers append to a single shared
log. Now, everyone who wants to read data from someone else can be sure to get
that data in the order it was produced by reading from that one log. Plus there
are N writers and N readers so getting the data to every where is <em>2N</em>. Now we
note that 2N &lt; N<sup>2</sup> if N > 2, so most of the time this is advantageous.</p>

<p>Now, the problem is that this single log is not going to be able to handle that
throughput, and it is going to get way too big way too fast. To build Kafka as
an implementation of this &ldquo;unified log&rdquo; concept, the key optimization is to
&ldquo;partition&rdquo; this log, meaning different pieces of it are written to different
places (machines), and each piece is written in duplicate to multiple machines.
In general we lose the total ordering across all processes, but in general,
this total ordering was literally more strict than could possibly be useful.</p>

<blockquote><p>This is the point where I stopped paying as much attention.</p></blockquote>

<p>Then Kreps goes on to talk about how important stream-processing is, because so
many of the services modern tech companies provide operate on a real-time feed
of events. Then he notes that log-table duality noted in the second paragraph
allows us to provide a reliable enriched event stream, ie. one that takes raw
events, joins each one with data from another table, and inserts some
maintained state like a counter.</p>

<p>Then Kreps notes that Kafka&rsquo;s cleverest provided algorithm for freeing up log
space, is to remove &ldquo;records whose primary key has a more recent update.&rdquo; The
naive provided algorithm is to discard elements that are more than <em>x</em> days
old.</p>

<p>Then he notes how most companies just exist to manipulate data in a distributed
system, and how building distributed systems in Java has to a large extent
become a problem of putting open source lego blocks like Zookeeper, Kafka,
Netty, etc. together. After that he summarizes and concludes.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Paxos as a Classroom]]></title>
    <link href="http://ethanp.github.io/blog/2015/05/18/paxos-as-a-classroom/"/>
    <updated>2015-05-18T19:28:49-05:00</updated>
    <id>http://ethanp.github.io/blog/2015/05/18/paxos-as-a-classroom</id>
    <content type="html"><![CDATA[<pre><code>multi-paxos as a classroom:
teacher := proposer
students := acceptors
all := learners

teacher to students:
    may I have your attention for the next 1:15 hrs?
    I'd like to teach youz guys all about "the paxos protocol"
    here is what I'm assuming you already know

each student to teacher:
    if not already busy for that time:
        yes, here's how much I actually already know about paxos
    else:
        my apologies, but I will be busy skimming facebook for the next 1:15
        so if there's something you want to tell me, post it on there

teacher to each student:
    given how far behind you are, these are the things you need to catch up on
    but also this is what I'm teaching now

each (alive &amp; correct) student to teacher:
    oh very cool!
    this is how much I now understand of all the stuff you've said

teacher:
    if the majority understands more than before:
        set new start point for next time's lesson
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simulating a Distributed System]]></title>
    <link href="http://ethanp.github.io/blog/2015/05/18/simulating-a-distributed-system/"/>
    <updated>2015-05-18T19:24:37-05:00</updated>
    <id>http://ethanp.github.io/blog/2015/05/18/simulating-a-distributed-system</id>
    <content type="html"><![CDATA[<p>For my Distributed Computing class at school, there were 3 projects that each
involved implementing a distributed protocol over a simulated distributed
cluster of computers that are only &lsquo;connected&rsquo; to one another in that they know
each other&rsquo;s IP address and must communicate over TCP sockets. For each of the
3 projects, I had a <em>completely</em> different method of implementing the system.</p>

<h3>Implementation One: A True Distributed System in Vanilla Java</h3>

<p>The first project (Three Phase Commit) was the only one for which I worked with
a partner. We were unclear how to attack the problem of building a distributed
system in a simple way, so we went ahead and implemented a truly distributable
Java application, in which you could spin up processes on any computer and it
would connect in to the master server, who would tell the new node the
listening ports of other servers in the cluster manually, etc. This turned out
to be perhaps overly ambitious. When a node was expecting a message from
someone else, it would fire a timer thread, which on completion would report to
the master to restart the failed process. This system did work properly
(somehow) but it seemed to be living-on-the-edge. It also required two weeks of
a lot of working on it and learning aspects of Java, unit testing, mocks, which
<code>Exception</code> would get thrown by which network event &amp; when, etc.</p>

<h3>Implementation Two: Lightweight System Simulation</h3>

<p>For the second project (Paxos), I said &ldquo;Hooey&rdquo; to all the Java hubbub, which
while I enjoyed its low-level-ness, forcing me to peak further under the hood,
it required a larger time commitment than I was prepared to make. I realized
that my class&rsquo;s requirements only specified that system &ldquo;nodes&rdquo; run
concurrently, share no memory, and talk over TCP. So in Scala, I made a <code>Node</code>
class state machine, and ran different instances of it on separate threads.
This was too easy though, and I was disappointed to find my implementation
complete more than two weeks before the due date.</p>

<h3>Implementation Three: Akka Cluster</h3>

<p>Akka Cluster is a Scala-based framework for building a distributed system, in
which you define the address of a set of &ldquo;seed&rdquo; nodes, of whom at least one is
supposed be available at all times. Then when other nodes start up, they become
a &ldquo;member&rdquo; of the cluster by contacting any seed node. So for me (the &ldquo;client&rdquo;
of Akka Cluster), all there is left to do is define the protocol to run on top
of the cluster. (In this case the protocol was the simple eventually-consistent
database protocol &ldquo;Bayou&rdquo;.)</p>

<p>Akka nodes follow the &ldquo;Actor Model&rdquo;, meaning they share no state with any other
part of your program, making them &ldquo;simple&rdquo; to run on remote machines (I didn&rsquo;t
try that, the docs say it is easy though). The only way actors can communicate
is via message passing, for which there is a dedicated syntax, <code>!</code>. For
example:</p>

<p><code>scala
case class MyMessage(data: DataElem)
anotherActor ! MyMessage(theData)
</code></p>

<p>The code above would have the actor running this code, send <code>anotherActor</code> an
instance of the case class <code>MyMessage</code> with the <code>DataElem</code> that was passed in.</p>

<p>Inter-actor communcation is guaranteed <em>FIFO</em> by Akka, meaning that for any
pair of actors <code>A, B</code>, if <code>A</code> sends <code>n</code> messages to <code>B</code>, <code>B</code> will receive those
messages in the same order that <code>A</code> sent them. NB this says nothing about the
order with respect to other actors in the system.</p>

<p>Using Akka trivialized all sorts of implementation details I&rsquo;d had to worry
about in the first project, and then ignored for the second project.</p>

<p>If there had been a 4th project for this class, it&rsquo;s clear to me that I would
use Akka again. For some reason my code ran <em>very</em> slowly, and it probably had
to do with some configuration-setting that I did not set in the Akka config
file. That was really the only problem I had that I did not fix. One problem I
did fix that took a while, was figuring out a good way to shut the system down.
There were various options discussed online, and eventually I found one that
worked for me, which was to call <code>system.shutdown()</code> on every instance System I
instantiate. Another option was to send <code>self ! PoisonPill</code> but for some reason
that didn&rsquo;t work. I guess different ones work for different situations.</p>
]]></content>
  </entry>
  
</feed>
