<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Networking | With Pith]]></title>
  <link href="http://ethanp.github.io/blog/categories/networking/atom.xml" rel="self"/>
  <link href="http://ethanp.github.io/"/>
  <updated>2015-12-27T00:52:17-06:00</updated>
  <id>http://ethanp.github.io/</id>
  <author>
    <name><![CDATA[Ethan Petuchowski]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Intro to HTTP/2]]></title>
    <link href="http://ethanp.github.io/blog/2015/10/26/intro-to-http-slash-2/"/>
    <updated>2015-10-26T16:11:59-05:00</updated>
    <id>http://ethanp.github.io/blog/2015/10/26/intro-to-http-slash-2</id>
    <content type="html"><![CDATA[<h2>The problem of HTTP/1.1</h2>

<h3>HTTP/1.1 is from an earlier Web</h3>

<p>For the past several years, Google, Mozilla, Akamai, the IETF, the academic
research community, and others have been engaged in efforts to reduce PLTs
experienced by users of the WWW. One bottleneck in apparent need of an update
is the now-&ldquo;ancient&rdquo; HTTP/1.1 (H1) protocol, published in 1999.</p>

<p>From the beginning, one of the major design goals of the original HTTP protocol
was simplicity to implement and adopt, to encourage growth of the WWW.
Evidently, this technique worked. However, over the past 16 years, the way
people create, distribute, and view pages on the WWW has changed drastically.
Pages today have far more Javascript, CSS, images, and other content to go
along with the vanilla HTML. In the course of this evolution, numerous issues
with H1 have come up, mostly pertaining to the number of sequential round-trips
it requires to fully download the data for each web page. These round-trips
introduce unnecessary latency.</p>

<!-- more -->


<p>Over the past 16 years, countermeasures, &ldquo;optional&rdquo; protocol alterations, and
application level workarounds have been suggested and implemented to reduce the
round-trip count and therefore latency of pages retrieved using H1.</p>

<h3>HTTP/1.1 PLT Optimizations</h3>

<p>Some optimizations servers and browsers use to lower PLTs seen by clients are
the following:</p>

<ol>
<li>Opening multiple TCP connections to request the download of multiple
required web page resources in parallel.</li>
<li>Inlining and concatenating scripts and stylesheets to reduce the number of
requests.</li>
<li><em>HTTP pipelining</em>, in which multiple requests are sent by the browser over a
single TCP connection before waiting for responses to any, then the server
sends all of the responses back in the same order.</li>
</ol>


<p>HTTP pipelining was an idea that did not work out. It seemed like a logical
approach to improve HTTP performance by reducing latency. However, in reality,
HOL blocking became an even greater issue then it already had been, and it also
led to issues with older proxies that are difficult to update. Nowadays, modern
browsers do not enable pipelining.</p>

<h2>HTTP/2 aims to address these issues</h2>

<p>The main reason multiple resources can&rsquo;t be <em>multiplexed</em> (downloaded in
parallel) over a single TCP connection in H1 is because it is an ASCII
protocol. Being an ASCII protocol means that there is no easy way to specify
how to demultiplex those responses with a parser.</p>

<p>To address this, HTTP/2 (H2) is a <em>binary</em> protocol that <em>can</em> easily multiplex
multiple requests and responses through a single TCP connection. It does this
using a new <em>binary framing layer</em>, in which responses are broken into separate
<em>frames</em> and interleaved through the TCP socket.</p>

<p>Web designers have discovered that to yield the best user experience, the
server should transmit certain most-important resources first, as soon as they
are available to send (e.g. loaded from disk). H2 frames (and <em>streams</em>) have
an (optional) <code>priority</code> field to allow the application developer (and server
writer) to bias the ordering of frames sent through the socket. For example,
one may want to ensure that <code>.html</code> files have a higher priority than <code>.jpeg</code>
files because <code>.jpeg</code>s contain a lot of data and are not as crucial for showing
the user a <em>barebones</em> version of the page they requested.</p>

<h3>Brief History</h3>

<p>The current H2 specification (RFC 7540) is based primarily on the SPDY protocol
invented and first used at Google. Google is in a rather unique position to
conduct research on this topic because they write the code running large
proportion of both user&rsquo;s browsers, <em>as well as</em> the servers for a large
portion of the web pages those people visit. This allows them to run real
controlled experimental studies on web traffic, to try to guage the best way to
speed up the Web.</p>

<p>Many have voiced concerns that Google&rsquo;s ideas are welcomed to quickly by the
standards committee. However, supporters are eager to get the ball rolling on
any good ideas, and point to the fact that Google already has <em>results</em>.</p>

<p>Note that some of the experimental results below were actually obtained using
SPDY rather than H2, but we will not concern ourselves with that because they
are the same in essence. Google Chrome still supports SPDY, but has claimed it
will remove support in 2016 so that there are not two competing
standardizations of basically the same protocol.</p>

<p>In reality, in my Chrome browser, using the &ldquo;HTTP/2 and SPDY indicator&rdquo;
extension, I can see that Google&rsquo;s search results and YouTube videos are served
over SPDY/3 running on top of their still-in-research QUIC protocol which is
meant to replace TCP as the transport layer protocol underneath HTTP. The
&ldquo;indicator&rdquo; reveals that many websites are in fact already being served over
H2, including Twitter. I hope to explore what exactly QUIC does, promises, and
delivers further in my research if there is time and space for it.</p>

<h3>Experimental Results</h3>

<p>Experiments investigating relative performance differences between H1 and H2
have yielded contradictory results (Wang et al.). In (Wang et al.), they found
that H2 generally outperforms H1, except when the task is to transmit <em>large</em>
objects over a <em>high-loss</em> connection. One of the goals in defining H2 is that
it is supposed to be easy to swap-in in-place of H1. This finding indicates
that especially with respect to mobile phones, the H1 optimization techniques
of inlining and concatenating web page resources is the wrong way to
improve performance for H2.</p>

<h3>HTTP for Mobile</h3>

<p>With respect to mobile devices, there are multiple problems with HTTP that are
<em>not</em> addressed by H2 (Erman et al.).</p>

<p>First of all, TCP congestion window part of congestion avoidance (<code>cwnd</code> and
<code>ssthresh</code>) makes it so that dropping a single TCP datagram leads to a
drastically reduced throughput. This is because TCP assumes the packet was
dropped due to network congestion, when in reality, it could have been for any
of the wireless-specific issues (multipath propagation, etc.)</p>

<p>Secondly, bad interactions between the 3G &amp; LTE MAC state machine timeouts and
modern default TCP timeouts and mechanisms lead to datagram <em>retransmissions</em>
with further resets on congestion window state variables, resulting in a
drastically negative impact on throughput.</p>

<h3>Research is needed</h3>

<p>From the system administrators' perspective, it is still difficult to decide
whether enabling H2 on one&rsquo;s servers is going to have a positive impact on
performance <em>at all</em> (Varvello et al.). The following questions still do not
have good enough answers to make answering that decision easy.</p>

<ol>
<li>What changes to the infrastructure and optimization pipeline are needed to
provide a significant benefit over H1?</li>
<li>What are the best algorithms for leveraging H2&rsquo;s new capabilities for
<em>server push</em> and <em>prioritization</em>?</li>
<li>Why do experiments by different research groups yield such a wide disparity
in results?</li>
<li>Are we unlikely to see any real PLT improvements until we improve the
underlying transport layer protocol?</li>
<li>In what ways is the problem different for mobile?

<ul>
<li>What changes need to be made in the mobile-specific scenario, viz. where
interference, low bandwidth, high latency, and battery life
considerations are major concerns?</li>
</ul>
</li>
</ol>


<h2>Glossary</h2>

<ul>
<li><strong>IETF</strong> (Internet Engineering Task Force) &mdash; a standards organization for
the Internet, which produces &ldquo;RFC"s (requests for comment) specifying some of
the crucial internet protocols, such as HTTP, TCP, and TLS.</li>
<li><strong>PLT</strong> (Page Load Time) &mdash; the duration between the time at which a user
submits a request for a web page, and the time at which she receives the last
byte of data needed to represent that web page correctly</li>
<li><strong>WWW</strong> (World Wide Web) &mdash; a decentralized collection of resources,
requested and transmitted using <em>HTTP</em></li>
<li><strong>HTTP</strong> (HyperText Transfer Protocol) &mdash; a protocol specifying the way an
HTTP <em>client</em> may upload, download, update, etc. documents on an HTTP
<em>server</em>. Often used for downloading <em>HTML</em> in particular.</li>
<li><strong>TCP</strong> (Transmission Control Protocol) &mdash; a protocol which provides an
application the abstraction of having a reliable pipe across the Internet
into/from which it may send/receive ordered sequences of bytes</li>
<li><strong>HOL blocking</strong> (head-of-line blocking) &mdash; when multiple messages are being
sent, but due to imposed FIFO ordering, messages ready to be sent must wait
for an earlier message which is taking a long time</li>
</ul>


<h2>References</h2>

<ul>
<li>Erman, Jeffrey, et al. &ldquo;Towards a SPDY'ier mobile web?.&rdquo; <em>Proceedings of the
ninth ACM conference on Emerging networking experiments and technologies.
ACM</em>, 2013.</li>
<li>Grigorik, Ilya. High Performance Browser Networking: What every web developer
should know about networking and web performance. <em>O'Reilly Media, Inc.</em>, 2013.</li>
<li>Roth, Gregor. &ldquo;HTTP/2 for Java Developers&rdquo;. Retrieved from
<a href="http://www.javaworld.com/article/2916548/java-web-development/http-2-for-">http://www.javaworld.com/article/2916548/java-web-development/http-2-for-</a>
java-developers.html on October 8, 2015.</li>
<li>Stenberg, Daniel aka. bagder. <em>http2 explained</em>, retrieved October 8, 2015;
downloaded as MOBI.</li>
<li>Varvello, Matteo, et al. &ldquo;To HTTP/2, or Not To HTTP/2, That Is The Question&rdquo;
arXiv preprint arXiv:1507.06562 (2015).</li>
<li>Wang, Xiao Sophia, et al. &ldquo;How speedy is SPDY.&rdquo; <em>Proc. of the 11th USENIX
Symposium on Networked Systems Design and Implementation (NSDI)</em>. 2014.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why the WiFi Sucks on the Porch]]></title>
    <link href="http://ethanp.github.io/blog/2015/09/24/why-the-wifi-sucks-on-the-porch/"/>
    <updated>2015-09-24T16:31:30-05:00</updated>
    <id>http://ethanp.github.io/blog/2015/09/24/why-the-wifi-sucks-on-the-porch</id>
    <content type="html"><![CDATA[<h2>Why is WiFi so slow on the porch?</h2>

<p>The problem at my house is that WiFi connectivity is generally fine inside the
house, but while sitting on the porch it is nearly impossible for anyone to
browse the Hinternets. I think a lesson of my <a href="http://www.cs.utexas.edu/~lili/classes/F15-CS386W/">Wireless Networking</a> course
explains this observation.</p>

<p>In Wireless networking we have the situation called the <a href="http://www.wikiwand.com/en/Hidden_node_problem"><strong>Hidden Terminal
Problem</strong></a>, which is the following. Node <code>A</code> is too far from node <code>C</code> to
hear its transmissions, but both are in range of node <code>B</code> which sits between
<code>A</code> and <code>C</code>. Suppose <code>C</code> is currently transmitting data to <code>B</code>. Now <code>A</code> checks
whether any transmissions are currently happening, and finds that there are
none (because it is out of range of <code>C</code>). So <code>A</code> goes ahead and sends data to
<code>B</code>. Now <code>B</code> can&rsquo;t understand either data packet because they collided and
interfered with each other in an unrecoverable way because they were both sent
in the same channel.</p>

<p>I think the porch scenario is simply an example of the <em>Hidden Terminal
Problem</em> above. In my room, my laptop can hear many of my neighbors' WiFi LAN
networks, but it&rsquo;s the same set that my WiFi router sitting in the closet can
hear. However outside, where there&rsquo;s less cause for signal attenuation, my
laptop can hear many more WiFi LAN networks than the router inside. So the
router checks whether there is congestion, doesn&rsquo;t hear any, and sends the
data. But there <em>is</em>, in fact, congestion, and my computer doesn&rsquo;t receive the
data properly. The data is therefore not <em>ACKd</em>, the router times out on the
<em>ACK</em>, and has to retransmit, and so on. This makes for a <em>far</em> slower
Hinterconnectivity outside on the porch than in my room.</p>

<p>Maybe the lesson learnt is that the WiFi router should be situated in a place
where it can hear more of the outside noise so that it can compensate better
for that noise.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Basics of Wireless Communication]]></title>
    <link href="http://ethanp.github.io/blog/2015/09/07/basics-of-wireless-communication/"/>
    <updated>2015-09-07T17:45:58-05:00</updated>
    <id>http://ethanp.github.io/blog/2015/09/07/basics-of-wireless-communication</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been doing the readings for my <a href="http://www.cs.utexas.edu/~lili/classes/F15-CS386W/">Wireless Networking course</a> at
UTexas, and in the process have dug into much of the basics of radios and
networks that I had ignored in the past. Here, I will try briefly describe what
I have learned. Maybe not everything I will say here is exactly correct, but I
think it&rsquo;s at least <em>mostly</em> correct.</p>

<p>Let&rsquo;s try to start somewhere near the beginning. Our <strong>goal</strong> is to transfer a
<em>information</em> from one location <code>LocSND</code> to another <code>LocRCV</code> <em>conveniently</em>.
The way we will accomplish that is by having <code>LocSND</code> manipulate the
<em>electromagnetic field</em> around <code>LocRCV</code>. More specifically, we will <em>encode</em> a
binary <em>dataframe</em> as <em>modulations</em> of a <em>radio signal</em> around a pre-determined
<em>carrier frequency</em>.</p>

<p>How do we <em>do</em> that?</p>

<!-- more -->


<p>We use an LRC circuit to make electrons oscillate in an
antenna. These oscillating electrons ram into loose and excitable electrons in
the antenna&rsquo;s metal, this releases a photon at a particular frequency. Globally
(i.e. within the entire transmitting antenna), enough photons are being
released that it seems to an external observer looking at the produced
electromagnetic (EM) field like there is a continuous signal being emitted.</p>

<p>So we&rsquo;re sending these EM ripples, which are generally at our carrier
frequency. However, if we just sent a basic frequency, there would be no
<em>information</em> in there, so we have to <em>modulate</em> it. We can modulate its
amplitude (A), phase (phi), and frequency (omega), the 3 free
parameters of the equation (in the top left of the equation in the following
gif from &ldquo;sengpielaudio&rdquo;)</p>

<p><img src="http://www.sengpielaudio.com/Sinuskurve01.gif" alt="sine wave" /></p>

<p>This would give us
1. <strong>Carrier frequency</strong> &mdash;&ndash; the EM frequency <em>inside</em> which our signal is
  encoded
2. <strong>amplitude shift keying (ASK)</strong> &mdash; send signal at <em>carrier frequency</em> by
   modulating the signal&rsquo;s <em>amplitude</em>
3. <strong>frequency shift keying (FSK)</strong> &mdash; similar but modulates <em>frequency</em>
4. <strong>phase shift keying (PSK)</strong> &mdash; again, but modulates <em>phase</em></p>

<p>One simple method would be to say our carrier frequency is 5 Hz, but our band
is actually [4,6] Hz. So whenever the signal is 4 Hz, that means I&rsquo;m sending a
0, and if the signal is 6 Hz, it means I&rsquo;m sending a 1, and a new digit starts
every 1 ms. That would be an example of <strong>FSK</strong>.</p>

<p>A fundamental problem that we must solve is that all senders and receivers of
information via EM fields with their antenna(s) are sharing the a single
<em>medium</em> for transmitting that field (viz. the air, etc.). So if <code>LocSND</code> sends
a message to <code>LocRCV_1</code>, then <code>LocRCV_2</code> sitting one foot away can hear that
message loud and clear. This leads to three major issues: <strong>security</strong>,
<strong>multiplexing</strong>, and <strong>interference</strong>.</p>

<p>To <strong>multiplex</strong> means to send multiple distinct signals through a single
channel. How are we going to send distinct signals to receivers 1 and 2 in such
a way that both can understand the signal meant for them? We can chop up the
frequency band that our transmitter can use into 2 smaller bands, and use each
of those bands as separate carriers. Then we tune the receivers to pick up
frequencies in their respective bands. This is what is called <strong>frequency
division multiplexing (FDM)</strong>, but we can also multiplex across space, time,
and <em>code</em>.</p>

<p>Of course, I&rsquo;ve only scratched the very surface of what&rsquo;s going on here, but
that&rsquo;s all the time I&rsquo;ve got.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Akamai Does]]></title>
    <link href="http://ethanp.github.io/blog/2015/06/10/what-akamai-does/"/>
    <updated>2015-06-10T21:23:31-05:00</updated>
    <id>http://ethanp.github.io/blog/2015/06/10/what-akamai-does</id>
    <content type="html"><![CDATA[<p>I met someone at a hack night worked for Akamai. He was a cool dude, so I was
curious what Akamai does. For whatever reason I ended up reading a paper cited
as so:</p>

<blockquote><p>Nygren, Erik, Ramesh K. Sitaraman, and Jennifer Sun. “The akamai network: a
platform for high-performance internet applications.” ACM SIGOPS Operating
Systems Review 44.3 (2010): 2–19.</p></blockquote>

<p>For whatever reason, everything I know about Akamai is from this paper. I&rsquo;m not
in any way afiliated with Akamai, etc., though the paper is basically a badly
designed advertising pamphlet for their services. A small number of sentences
in this summary may have been lifted directly from that paper. You can consider
this whole post a paraphrasing of the paper. <strong>The intent of this post is to
tell you everything important that I learned from the paper</strong> in a form that is
<em>way</em> easier to digest than you reading the paper itself. To that end, this
document is maybe 2 pages long, and the original is 17. Clearly much of the
detail has been removed, but the gist remains. If that appeals to you, welcome
aboard! Note that the paper is from 2010, so is probably already out of date.</p>

<h2>Introduction</h2>

<p>Akamai invented the <em>Content Delivery Network</em> (CDN) concept in the 1990s,
because the raw naive Internet implementation is too slow to conduct a global
business. As of 2010, Akamai delivers 15-20% of global Web traffic.</p>

<h3>The Interwebs is a dangerous place</h3>

<!-- more -->


<p>For a web app, downtime and high latency is <em>very</em> costly. Customers won&rsquo;t go
to your page unless they can see your content <em>right this second</em>. The Internet
itself can provide no reliability or performance gaurantees.</p>

<p>The Internet is composed of 1000s of individual networks, the largest having
only 5% of Internet access traffic. It takes 650 networks to get to 90% of all
access traffic. The Internet-access pricing structure happens to result in a
situation in which connections between networks (&ldquo;peering points&rdquo;) are
bottlenecks causing packet loss and increased latency.</p>

<p>The protocol ISPs use to exchange rounting information (BGP) is bad and subject
to misuse. Internet outages and partitions are regular occurrences. The strict
ACK policy for TCP adds enough overhead to make video streaming over TCP
impractical. The high proportion of people still using IE6 means any improved
algorithms that get implemented have to be backwards compatible with that one
silly browser.</p>

<h2>Content Delivery Networks</h2>

<p>Originally a CDN&rsquo;s purpose was to cache static site content at the &ldquo;edge&rdquo; of
the Internet, close to end users, to avoid middle-mile bottlenecks. Now they
accelerate entire web apps and provide HD live streaming media. They provide
security, logging, diagnostics, reporting, and management tools</p>

<p>A <strong>delivery network</strong> is a <em>virutal network</em>, i.e. a software layer over the
actual Internet, to provide reliability, performance, scalability, and
security. It requires no client software or changes to the underlying networks.
Akamai&rsquo;s network is made from tens of thousands of globally deployed servers
running sophisticated algorithms to enable faster content delivery.</p>

<h3>In Greater Detail</h3>

<p>When a user enters a URL into their browser, their DNS routes them to an Akamai
DNS, which in turn gives them the IP address of an <strong>edge server</strong> chosen via
machine learning algorithm. The edge server acts as a cache for the <strong>origin
server</strong>, and if it needs new data, it uses an especially reliable and
performant <strong>transport system</strong> (described later on), which is a network of
internal nodes who know best how to connect the <em>edge</em> back to the <em>origin</em>.</p>

<p>The <strong>transport system</strong> connects <em>edge</em> to <em>origin</em> servers with a cache
pyramid of clusters. Streaming video is <em>branched out</em> to the edge clusters by
intermediate layers of <em>reflectors</em>.</p>

<p>Edge servers communicate to each other via their own chosen path optimization
rather than the default one chosen by BGP, and use dynamically optimized TCP
parameters. They can also intelligently prefetch and cache content from the
origin right before before it is requested by the user.</p>

<p>Akamai&rsquo;s EdgeComputing product allows you to distribute your web application
<em>itself</em> &ldquo;to the <em>edge</em>&rdquo;, which is great for content aggregation, product
catalogs (dynamic access of static content), data validation, and data input
batching. It&rsquo;s not great for apps relying heavily on transactional databases
because they still must communicate with the origin server.</p>
]]></content>
  </entry>
  
</feed>
