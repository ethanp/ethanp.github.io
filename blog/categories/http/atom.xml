<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Http | With Pith]]></title>
  <link href="http://ethanp.github.io/blog/categories/http/atom.xml" rel="self"/>
  <link href="http://ethanp.github.io/"/>
  <updated>2016-05-12T15:16:35-07:00</updated>
  <id>http://ethanp.github.io/</id>
  <author>
    <name><![CDATA[Ethan Petuchowski]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Very Basics of Jetty]]></title>
    <link href="http://ethanp.github.io/blog/2015/10/27/very-basics-of-jetty/"/>
    <updated>2015-10-27T09:09:50-07:00</updated>
    <id>http://ethanp.github.io/blog/2015/10/27/very-basics-of-jetty</id>
    <content type="html"><![CDATA[<h3>Jetty has <em>cutting edge</em> HTTP/2 support</h3>

<p>For my Wireless Networking project, I&rsquo;m going to compare HTTP/1.1 and HTTP/2
with respect to performance metrics when talking to a mobile phone over the
cellular network. There are not so many <a href="https://github.com/http2/http2-spec/wiki/Implementations">implementations</a> of HTTP/2 right
now, and some of them seem a bit shaky. At the end of the day, it seems to me
that the easiest way to run this sort of experiment in a reliable fashion is to
use Java&rsquo;s <a href="http://www.eclipse.org/jetty/">Jetty</a> project. It has well-tested HTTP/1.1 support, many
heavyweight framework users, implements HTTP/2&rsquo;s server push and all sorts of
HTTP/2 negotation mechanisms, and I like static types.</p>

<h3>Jetty is hard to find tutorials for</h3>

<p>So I need to learn the basics of Jetty; and there&rsquo;s a lot to learn, and I
haven&rsquo;t found a stellar resource, so I&rsquo;ve been reading the <a href="http://www.eclipse.org/jetty/documentation/current/embedding-jetty.html">embedded
examples</a>, which are decent. I&rsquo;m usng &ldquo;embedded&rdquo; Jetty because that means
I can write type-safe Java rather than XML. Perhaps XML would be a good choice
for a long-standing app, but I&rsquo;m making a prototype and it&rsquo;s easier to just
write code.</p>

<p>Here&rsquo;s a brief overview of what I&rsquo;ve learned so far, which may come in handy
for someone else wanting to understand the very basics of Jetty (version 9).
This is not a detailed overview because I don&rsquo;t know what I&rsquo;m talking about.
I&rsquo;m just explaining the things I have learned from the tutorial linked above
and some mucking around.</p>

<!-- more -->


<h3>Jetty has a few large architectural components</h3>

<p>The main things you need to deal with in Jetty are <code>Server</code>s, <code>Handler</code>s, and
<code>Connector</code>s.</p>

<p>The <code>Server</code> manages your entire web site. It does this by connecting
<code>Connector</code>s to <code>Handler</code>s. The default <code>Connector</code>, <code>ServerConnector</code> responds
to vanilla HTTP/1.1 requests. If you try to make a request via <code>https</code> to a
<code>ServerConnector</code> without <code>https</code> support, in Chrome you will see the following
error message</p>

<p>```text
ERR_SSL_PROTOCOL_ERROR</p>

<p>Unable to make a secure connection to the server. This may be a problem with
the server, or it may be requiring a client authentication certificate that you
don&rsquo;t have.
```</p>

<h4>Handler</h4>

<p>You may want a chain of <code>Handler</code>s that will be tried one after another until
one is found to be appropriate for handling the current request</p>

<p><code>java
HandlerList handlers = new HandlerList();
handlers.setHandlers(new Handler[] { resource_handler, new DefaultHandler() });
</code></p>

<p>The <code>DefaultHandler</code> will simply return <code>404</code>s for everything. Jetty will keep trying <code>Handler</code>s in the list until one of them performs</p>

<p><code>java
baseRequest.setHandled(true);
</code></p>

<p>Looking at the <code>DefaultHandler</code>&rsquo;s source, we can see that indeed, in the
<code>handle</code> method, this is the <em>first</em> thing it does.</p>

<h4>Connector</h4>

<p>Each <code>Connector</code> instance can respond to a particular <em>protocol</em> at a
particular <em>host</em> on a particular <em>port</em>. So if you want to respond to <code>https</code>
requests as well as vanilla <code>http</code>, you&rsquo;re going to need another <code>Connector</code>.</p>

<h4>Routing</h4>

<p>A <code>ContextHandler</code> is used to do what in Rails would be called &ldquo;routing&rdquo;. This
is where you associate path&rsquo;s in the HTTP request header to the right
controller. After you&rsquo;ve created your <code>ContextHandler</code>s and set their
<code>contextPath</code>s, you need to do the following</p>

<p><code>java
Server server = new Server(8080);
//...
ContextHandlerCollection contexts = new ContextHandlerCollection();
contexts.setHandlers(new Handler[] { context0, context1, ... });
server.setHandler(contexts);
</code></p>

<p>This means the server is going to ask the <code>ContextHandlerCollection</code> for the
first <code>ContextHandler</code> that matches the path specified on the incoming request.</p>

<h3>Conclusion: Jetty feels dated compared to Ruby on Rails</h3>

<p>So far, I find Jetty surprisingly nice. I&rsquo;m
starting to appreciate the fact that it is written in Java and it is open
source. It&rsquo;s so different from Ruby on Rails and Node.js because there is not a
lot of magical mystery code running in the background whose source is difficult
to find. The advantage of those other frameworks is that they have much higher
level APIs. I find myself wrapping Jetty methods into my own methods that do
what in Rails would have been done automatically. Now I understand the draw of
Rails&rsquo;s &ldquo;convention over configuration&rdquo; and &ldquo;don&rsquo;t repeat yourself&rdquo;. I didn&rsquo;t
realize how much configuration and repeating yourself was necessary back in the
Java days. And that leads me to my next point, that writing Jetty feels like
writing 10 year old code. I wasn&rsquo;t coding 10 years ago, but I imagine you had
to explicitly wire every last thing together by hand over and over again, as
you do in Jetty.</p>

<p>Unlike Rails or iOS, basic Jetty is not a Model View Controller framework. It&rsquo;s
just handlers on a server, more like Node.js. Personally, I like MVC out of
ignorance because I assume people who came up with it thought the &ldquo;application
framework&rdquo; way of doing thigs was &lsquo;bad&rsquo;, and I tend to trust people who don&rsquo;t
like the &lsquo;old&rsquo; way of doing things. That said, I am not making a database based
application here so I will not evaluate this difference any further.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to HTTP/2]]></title>
    <link href="http://ethanp.github.io/blog/2015/10/26/intro-to-http-slash-2/"/>
    <updated>2015-10-26T14:11:59-07:00</updated>
    <id>http://ethanp.github.io/blog/2015/10/26/intro-to-http-slash-2</id>
    <content type="html"><![CDATA[<h2>The problem of HTTP/1.1</h2>

<h3>HTTP/1.1 is from an earlier Web</h3>

<p>For the past several years, Google, Mozilla, Akamai, the IETF, the academic
research community, and others have been engaged in efforts to reduce PLTs
experienced by users of the WWW. One bottleneck in apparent need of an update
is the now-&ldquo;ancient&rdquo; HTTP/1.1 (H1) protocol, published in 1999.</p>

<p>From the beginning, one of the major design goals of the original HTTP protocol
was simplicity to implement and adopt, to encourage growth of the WWW.
Evidently, this technique worked. However, over the past 16 years, the way
people create, distribute, and view pages on the WWW has changed drastically.
Pages today have far more Javascript, CSS, images, and other content to go
along with the vanilla HTML. In the course of this evolution, numerous issues
with H1 have come up, mostly pertaining to the number of sequential round-trips
it requires to fully download the data for each web page. These round-trips
introduce unnecessary latency.</p>

<!-- more -->


<p>Over the past 16 years, countermeasures, &ldquo;optional&rdquo; protocol alterations, and
application level workarounds have been suggested and implemented to reduce the
round-trip count and therefore latency of pages retrieved using H1.</p>

<h3>HTTP/1.1 PLT Optimizations</h3>

<p>Some optimizations servers and browsers use to lower PLTs seen by clients are
the following:</p>

<ol>
<li>Opening multiple TCP connections to request the download of multiple
required web page resources in parallel.</li>
<li>Inlining and concatenating scripts and stylesheets to reduce the number of
requests.</li>
<li><em>HTTP pipelining</em>, in which multiple requests are sent by the browser over a
single TCP connection before waiting for responses to any, then the server
sends all of the responses back in the same order.</li>
</ol>


<p>HTTP pipelining was an idea that did not work out. It seemed like a logical
approach to improve HTTP performance by reducing latency. However, in reality,
HOL blocking became an even greater issue then it already had been, and it also
led to issues with older proxies that are difficult to update. Nowadays, modern
browsers do not enable pipelining.</p>

<h2>HTTP/2 aims to address these issues</h2>

<p>The main reason multiple resources can&rsquo;t be <em>multiplexed</em> (downloaded in
parallel) over a single TCP connection in H1 is because it is an ASCII
protocol. Being an ASCII protocol means that there is no easy way to specify
how to demultiplex those responses with a parser.</p>

<p>To address this, HTTP/2 (H2) is a <em>binary</em> protocol that <em>can</em> easily multiplex
multiple requests and responses through a single TCP connection. It does this
using a new <em>binary framing layer</em>, in which responses are broken into separate
<em>frames</em> and interleaved through the TCP socket.</p>

<p>Web designers have discovered that to yield the best user experience, the
server should transmit certain most-important resources first, as soon as they
are available to send (e.g. loaded from disk). H2 frames (and <em>streams</em>) have
an (optional) <code>priority</code> field to allow the application developer (and server
writer) to bias the ordering of frames sent through the socket. For example,
one may want to ensure that <code>.html</code> files have a higher priority than <code>.jpeg</code>
files because <code>.jpeg</code>s contain a lot of data and are not as crucial for showing
the user a <em>barebones</em> version of the page they requested.</p>

<h3>Brief History</h3>

<p>The current H2 specification (RFC 7540) is based primarily on the SPDY protocol
invented and first used at Google. Google is in a rather unique position to
conduct research on this topic because they write the code running large
proportion of both user&rsquo;s browsers, <em>as well as</em> the servers for a large
portion of the web pages those people visit. This allows them to run real
controlled experimental studies on web traffic, to try to guage the best way to
speed up the Web.</p>

<p>Many have voiced concerns that Google&rsquo;s ideas are welcomed to quickly by the
standards committee. However, supporters are eager to get the ball rolling on
any good ideas, and point to the fact that Google already has <em>results</em>.</p>

<p>Note that some of the experimental results below were actually obtained using
SPDY rather than H2, but we will not concern ourselves with that because they
are the same in essence. Google Chrome still supports SPDY, but has claimed it
will remove support in 2016 so that there are not two competing
standardizations of basically the same protocol.</p>

<p>In reality, in my Chrome browser, using the &ldquo;HTTP/2 and SPDY indicator&rdquo;
extension, I can see that Google&rsquo;s search results and YouTube videos are served
over SPDY/3 running on top of their still-in-research QUIC protocol which is
meant to replace TCP as the transport layer protocol underneath HTTP. The
&ldquo;indicator&rdquo; reveals that many websites are in fact already being served over
H2, including Twitter. I hope to explore what exactly QUIC does, promises, and
delivers further in my research if there is time and space for it.</p>

<h3>Experimental Results</h3>

<p>Experiments investigating relative performance differences between H1 and H2
have yielded contradictory results (Wang et al.). In (Wang et al.), they found
that H2 generally outperforms H1, except when the task is to transmit <em>large</em>
objects over a <em>high-loss</em> connection. One of the goals in defining H2 is that
it is supposed to be easy to swap-in in-place of H1. This finding indicates
that especially with respect to mobile phones, the H1 optimization techniques
of inlining and concatenating web page resources is the wrong way to
improve performance for H2.</p>

<h3>HTTP for Mobile</h3>

<p>With respect to mobile devices, there are multiple problems with HTTP that are
<em>not</em> addressed by H2 (Erman et al.).</p>

<p>First of all, TCP congestion window part of congestion avoidance (<code>cwnd</code> and
<code>ssthresh</code>) makes it so that dropping a single TCP datagram leads to a
drastically reduced throughput. This is because TCP assumes the packet was
dropped due to network congestion, when in reality, it could have been for any
of the wireless-specific issues (multipath propagation, etc.)</p>

<p>Secondly, bad interactions between the 3G &amp; LTE MAC state machine timeouts and
modern default TCP timeouts and mechanisms lead to datagram <em>retransmissions</em>
with further resets on congestion window state variables, resulting in a
drastically negative impact on throughput.</p>

<h3>Research is needed</h3>

<p>From the system administrators' perspective, it is still difficult to decide
whether enabling H2 on one&rsquo;s servers is going to have a positive impact on
performance <em>at all</em> (Varvello et al.). The following questions still do not
have good enough answers to make answering that decision easy.</p>

<ol>
<li>What changes to the infrastructure and optimization pipeline are needed to
provide a significant benefit over H1?</li>
<li>What are the best algorithms for leveraging H2&rsquo;s new capabilities for
<em>server push</em> and <em>prioritization</em>?</li>
<li>Why do experiments by different research groups yield such a wide disparity
in results?</li>
<li>Are we unlikely to see any real PLT improvements until we improve the
underlying transport layer protocol?</li>
<li>In what ways is the problem different for mobile?

<ul>
<li>What changes need to be made in the mobile-specific scenario, viz. where
interference, low bandwidth, high latency, and battery life
considerations are major concerns?</li>
</ul>
</li>
</ol>


<h2>Glossary</h2>

<ul>
<li><strong>IETF</strong> (Internet Engineering Task Force) &mdash; a standards organization for
the Internet, which produces &ldquo;RFC"s (requests for comment) specifying some of
the crucial internet protocols, such as HTTP, TCP, and TLS.</li>
<li><strong>PLT</strong> (Page Load Time) &mdash; the duration between the time at which a user
submits a request for a web page, and the time at which she receives the last
byte of data needed to represent that web page correctly</li>
<li><strong>WWW</strong> (World Wide Web) &mdash; a decentralized collection of resources,
requested and transmitted using <em>HTTP</em></li>
<li><strong>HTTP</strong> (HyperText Transfer Protocol) &mdash; a protocol specifying the way an
HTTP <em>client</em> may upload, download, update, etc. documents on an HTTP
<em>server</em>. Often used for downloading <em>HTML</em> in particular.</li>
<li><strong>TCP</strong> (Transmission Control Protocol) &mdash; a protocol which provides an
application the abstraction of having a reliable pipe across the Internet
into/from which it may send/receive ordered sequences of bytes</li>
<li><strong>HOL blocking</strong> (head-of-line blocking) &mdash; when multiple messages are being
sent, but due to imposed FIFO ordering, messages ready to be sent must wait
for an earlier message which is taking a long time</li>
</ul>


<h2>References</h2>

<ul>
<li>Erman, Jeffrey, et al. &ldquo;Towards a SPDY'ier mobile web?.&rdquo; <em>Proceedings of the
ninth ACM conference on Emerging networking experiments and technologies.
ACM</em>, 2013.</li>
<li>Grigorik, Ilya. High Performance Browser Networking: What every web developer
should know about networking and web performance. <em>O'Reilly Media, Inc.</em>, 2013.</li>
<li>Roth, Gregor. &ldquo;HTTP/2 for Java Developers&rdquo;. Retrieved from
<a href="http://www.javaworld.com/article/2916548/java-web-development/http-2-for-">http://www.javaworld.com/article/2916548/java-web-development/http-2-for-</a>
java-developers.html on October 8, 2015.</li>
<li>Stenberg, Daniel aka. bagder. <em>http2 explained</em>, retrieved October 8, 2015;
downloaded as MOBI.</li>
<li>Varvello, Matteo, et al. &ldquo;To HTTP/2, or Not To HTTP/2, That Is The Question&rdquo;
arXiv preprint arXiv:1507.06562 (2015).</li>
<li>Wang, Xiao Sophia, et al. &ldquo;How speedy is SPDY.&rdquo; <em>Proc. of the 11th USENIX
Symposium on Networked Systems Design and Implementation (NSDI)</em>. 2014.</li>
</ul>

]]></content>
  </entry>
  
</feed>
