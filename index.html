
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>With Pith</title>
  <meta name="author" content="Ethan Petuchowski">

  
  <meta name="description" content="I like to learn things, but I
often feel like time I spend learning things is wasted. It&rsquo;s hard to tell what info is going to be useful and &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://ethanp.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="With Pith" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">With Pith</a></h1>
  
    <h2>Ethan Petuchowski</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:ethanp.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/about">About</a></li>
  <li><a href="/portfolio">Portfolio</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/10/09/on-learning/">On Learning</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-10-09T15:03:32-07:00" pubdate data-updated="true">Oct 9<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://www.youtube.com/watch?v=Zjm8JeDKvdc">I like to learn things</a>, but I
often feel like time I spend learning things is wasted.</p>

<h3>It&rsquo;s hard to tell what info is going to be useful and what is fluff</h3>

<p>Classes in school (at all levels) lead to lots of wasted effort, because a lot of the stuff you&rsquo;re supposed to learn is simply not useful knowledge. For example, for one college exam, I had to name about 30 different rocks and minerals by sight, and the names are very complicated. People say: &ldquo;well just going through the process is teaching you how to think.&rdquo; I don&rsquo;t disagree, but I think that&rsquo;s a fallacy; learing to think and useful knowledge are not mutually exclusive. Useless knowledge includes specific dates, long names, irrelevant historical events, and other things we might in everyday life dismiss as &ldquo;trivia&rdquo;.</p>

<blockquote><p>In my experience, all academic disciplines have room to reduce the &ldquo;trivia&rdquo; overhead in their curricula.</p></blockquote>

<p>In college computer science classes, there is not a whole lot of trivia. However, their is a &ldquo;jump into abstraction&rdquo; that often left me confused. I quite often didn&rsquo;t understand <em>why</em> what I was learning was important. Edsger Dijkstra said we should teach the abstractions before rotting the students&#8217; brains with modern programming realities and deficiencies. That&rsquo;s a laudable mission, but problems still need to be better <em>motivated</em>.</p>

<h4>Difficult material with no motivation is not rewarding</h4>

<p>E.g. during my first Operating Systems course. Everything seemed way more complicated than anything I should ever be expected to know in real life. So I figured I would never end up needing to understand virtual memory, processes and threads, scheduling, networking, etc. In reality, I just had no idea what I was talking about, and that&rsquo;s why it should have been <em>motivated</em>. For example, I have since learned that the Linux kernel has a very interesting open source development ecosystem. They are making upgrades to the thing all the time that affect everyone developing most kinds of modern software. In addition, a whole lot of the different features of computers are motivated by internal business tool usecases, rather than home consumer usecases. Being a college student without a computer nerd background, I had no idea about any of that. Being taught to appreciate how important this stuff would end up being for me would have made me learn drastically more during the course of the class.</p>

<p>What I wanted at that time was for the material to be motivated with an example, like, &ldquo;let&rsquo;s build a program for running a medical radiation machine.&#8221;Now we&rsquo;re talking; we&rsquo;re going to need to get all the different low-level components right and make them fit together so that we can save lives!</p>

<p>What actually happened was similar in content, but not in objective. We were expected to read a very long and dry paper on the Therac-25, a radiation machine with concurrency issues that killed a few people in the 1980s. I spent a few hours trying to read the paper. One could say I was spending that time &ldquo;learning to think&rdquo;, but I think I spent that time &ldquo;getting nowhere&rdquo;. The whole time I was reading the paper, I was thinking: it would take me so long to get to the point of this paper, and I&rsquo;m not even going to get a whole lot out of it. No good. In the end I learned about the Therac-25 from Wikipedia, a source of information whose expected readership has a level of background knowledge more commensurate with my own. Then, a few years later, I had to read that paper again for a graduate operating systems class, and at that point I had sufficient background knowledge to simply read the paper and feel like I understood its content and learned important lessons about software engineering.</p>

<p>This example demonstrates the fundamental principle that the same content can lead to completely different learning outcomes for different people, and even for the same person at different points of time and (as we shall return to later) in different emotional moods.</p>

<h3>Some keys to not wasting effort</h3>

<ul>
<li>Have something in mind that you want to accomplish with your newly-obtained knowledge

<ul>
<li>E.g. &ldquo;I want to build the software for a medical radiation device&rdquo;</li>
</ul>
</li>
<li>Have someone (colleague) or some place (e.g. stack overflow) where you can ask questions when you get confused

<ul>
<li>Sometimes having another person just <em>explain the whole thing</em> in one shot face to face can lead you to simply <em>just get it</em></li>
</ul>
</li>
<li>Learn the relevant vocabulary for the field on wikipedia

<ul>
<li>For example take at least half an hour digging through linked topics until you have a general grasp of the various concerns and their names, and ideally how they relate to one another</li>
</ul>
</li>
<li>Skim liberally but don&rsquo;t expect to understand what you skim</li>
</ul>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/10/09/on-learning/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/06/19/first-glance-at-genomics-with-adam-and-spark/">First Glance at Genomics With ADAM and Spark</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-06-19T14:15:22-07:00" pubdate data-updated="true">Jun 19<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>At work, we have a Spark cluster. One of my first responsibilities was to make
it more reliable and efficient. So I looked on Github to see how people
actually use Spark, and what magic they use to get their clusters not to crash
in the process. This is how I found <a href="https://github.com/bigdatagenomics/adam/">ADAM</a>, &ldquo;a genomics analysis platform
built using Avro, Spark, and Parquet&rdquo;. Then I looked in the repo&rsquo;s
<em>contributors</em> list, and watched a few lectures by Frank Nothaft and Matt
Massie, two of the project&rsquo;s main contributors. What I heard there was pretty
cool.</p>

<p>In short, they&rsquo;re looking to build systems that will &ldquo;one day&rdquo; recommend more
effective treatments for diseases including cancer and Alzheimer&rsquo;s within an
hour of receiving a patient&rsquo;s DNA sample. They describe several components of
what needs to be done to make [research toward] this possible.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/06/19/first-glance-at-genomics-with-adam-and-spark/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/05/30/hdfs-output-stream-api-semantics/">Hdfs Output Stream Api Semantics</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-05-30T14:00:09-07:00" pubdate data-updated="true">May 30<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Writing to files can get tricky. You have to think about the semantics you
want, versus any performance imperatives, etc. Here, we look a briefly at the
Linux file system API, and then contrast it with a brief look at the Hadoop
File System (HDFS) Java API.</p>

<h2>Linux file API</h2>

<p>In the normal Linux file system API, there are various ways to &ldquo;flush&rdquo; a file.
Here are a few of the ones I have seen.</p>

<p>We have <code>fflush(3)</code>, which flushes all user-space buffers via the
stream&rsquo;s underlying write function. This data may still exist in the kernel
(e.g. buffer cache and page cache [since 2.4, Linux buffer cache usually just
points to an entry in the page cache <a href="">see quora</a>]).</p>

<p>We have <code>fsync(2)</code>, which flushes modified pages of data from the operating
system&rsquo;s buffer cache to the actual disk device, and blocks until this has
completed. Modified metadata (e.g. file size) is also written out to the
file&rsquo;s inode&rsquo;s metadata section.</p>

<p>We have <code>close(2)</code>, which closes a file descriptor, but does not cause
flushing of any kernel buffers.</p>

<p>We have <code>fclose(3)</code>, which closes the file descriptor, <em>and</em> flushes its <em>user
space</em> buffers (like <code>fflush(3)</code>).</p>

<p><a href="https://www.quora.com/What-is-the-major-difference-between-the-buffer-cache-and-the-page-cache/answer/Robert-Love-1?srid=zA4O">https://www.quora.com/What-is-the-major-difference-between-the-buffer-cache-and-the-page-cache/answer/Robert-Love-1?srid=zA4O</a></p>

<h3>References</h3>

<ul>
<li><a href="http://man7.org/linux/man-pages/man3/fflush.3.html">man fflush(3)</a></li>
<li><a href="http://man7.org/linux/man-pages/man2/fsync.2.html">man fsync(2)</a></li>
<li><a href="https://www.wikiwand.com/en/Inode#/POSIX_inode_description">wiki inode</a></li>
<li><a href="http://linux.die.net/man/2/close">man close(2)</a></li>
<li><a href="http://linux.die.net/man/3/fclose">man fclose(3)</a></li>
</ul>


<h2>Hadoop File System (HDFS) file Java API</h2>

<p>In this API the names of the functions are similar, but the semantics are
quite different.</p>

<p>In HDFS, a &ldquo;file&rdquo; is stored as a sequence of &ldquo;blocks&rdquo;, and each block is is
globally-configured to be e.g. either 64MB or 128MB in size. Each block is
separately stored on the configured number of machines, according to the
chosen HDFS &ldquo;replication factor&rdquo;. For the instance of Linux running on a
particular node in the HDFS cluster, a block is a file that Linux must track
just like it would any other file: with a page/buffer cache (see above),
inode, etc. Tracking and deciding which blocks belong to each HDFS file, and
on which nodes each of those blocks are stored is the responsibility of the
HDFS NameNode (i.e. the single master node).</p>

<p>But the whole block-level view of HDFS is not (directly) visible to the HDFS
client API. Instead, a client simply opens an <code>OutputStream</code> to a file by
telling the name node that it either wants to create a new file, or append to
an existing file. The NameNode responds with nodes that should accept the
first block of data. The client starts writing to the first DataNode willing
to take its data. That DataNode, pipelines this incoming data to the other
DataNodes responsible for replicating this block.</p>

<p>Similar to the Linux file system API above, just because bytes are being
&ldquo;written&rdquo; by the client, does <strong>not</strong> mean they&rsquo;ll necessarily:</p>

<ol>
<li>be visible to someone who now tries to the read the file</li>
<li>be reflected in the current metadata available about the file (which lives
in the NameNode)</li>
<li>survive crashes of</li>
<li>the client or</li>
<li>the DataNode(s)</li>
</ol>


<p>Similar to the Linux file system API above, we have a few methods we can use
to decide the buffering semantics we want of our pending writes.</p>

<p>We have <code>hflush()</code>, which flushes data in the client&rsquo;s user buffer all the way
out to the nodes which are responsible for storing the relevant <em>&ldquo;blocks&rdquo;</em> of
this file. The metadata in the NameNode is <strong>not</strong> updated. Data is <em>not</em>
necessily flushed from the DataNodes&#8217; buffer caches to the actual disk device.</p>

<p>We have <code>hsync()</code>, which is <em>just</em> an alias for <code>hflush</code>.</p>

<p>We have <code>close()</code>, which closes the stream, makes sure all the data has arrived
at all the relevant nodes, and updates the metadata in the NameNode (e.g.
updates the file-length as seen from the <code>hadoop fs -ls myFile.txt</code> command
line interface).</p>

<p>In my experience, <strong>it is not safe to be opening and closing the same files
from the same instance of the Hadoop client on different threads</strong>. Maybe I
was naive in thinking this would be OK, as the Linux man pages given above
seem to suggest that this would be problematic even with the direct Linux file
system API.</p>

<h3>References</h3>

<ul>
<li><a href="https://hadoop.apache.org/docs/r2.6.1/api/org/apache/hadoop/fs/FSDataOutputStream.html">HDFS output stream API</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/05/14/ramblings-on-insight/">Ramblings on Insight</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-05-14T14:46:12-07:00" pubdate data-updated="true">May 14<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I&rsquo;m re-designing a program I&rsquo;ve been working on for a few months. I&rsquo;ve
implemented a prototype for the new design and also started implementing it.
Because I haven&rsquo;t thought this through completely or written much of the code
yet, there is still room for fundamental issues to come up with plugging this
model into my codebase which will make it impossible for this major
refactoring to complete. But really, what I expect is that this model allows
us to express what is really going on in such a way that by looking at the
<em>names</em> of the components, we know <em>where</em> to start looking for code
describing <em>what</em> is really happening. If that is true, and we write function
names from the top-down (i.e. <strong>start with &ldquo;main&rdquo; and go down, as a breadth-
first search</strong>), then whole bunches of code will be isolated in that they
survive to create the capability of some unique higher-level function (or a
small set of functions).</p>

<p>Even though I have a clearer conception of how to go forward than I did when
first writing the program. I still find it hard to think through the whole
problem without just trying it. But if I just try it then I don&rsquo;t know what
I&rsquo;m doing. Then, after I learn what the pieces I need <em>are</em>, I can start from
the top-level design and then go down.</p>

<p>I don&rsquo;t know if there&rsquo;s a particular <em>moment</em> when I am <em>ready</em> to see the
problem more fully. In this case, it seemed to happen because I <em>had</em> to find
a better way. The program was going to be a lot of trouble to keep dealing
with if I didn&rsquo;t figure out a better way to name and organize the different
concerns it actually addresses. By naming and organizing things better, we get
a little &ldquo;registry&rdquo; of package, class, method, and value names that reveal the
solution&rsquo;s structure.</p>

<p>Refactoring can get a bit tedious. But maybe the most tedious bits are often
not really worth doing. I hope to build up a better intuition for it. But for
now, it&rsquo;s one of those things where I don&rsquo;t know the words to describe what
I&rsquo;m really making. I can see how knowing a bunch of &ldquo;patterns&rdquo; would make this
easier. Especially considering that the crux of the pipeline I implemented is
the &ldquo;observer&rdquo; pattern, one of the only patterns I know. But I think the main
thing is to just try things out, see what works, and what doesn&rsquo;t, then go
back and learn the &ldquo;patterns&rdquo; after I&rsquo;ve read and written a bunch of different
designs <em>in the code</em>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/05/14/form-in-main-follows-program-function/">Form in &#8216;Main&#8217; Follows Program Function</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-05-14T14:44:11-07:00" pubdate data-updated="true">May 14<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>My program is a pipeline that takes multiple data sources, transforms them,
mashes them together, and writes them to multiple locations. It does this in a
somewhat resilient way by using Kafka as an internal buffer and data bus.
However you would have no idea from the structure of the program that that is
what is going on. In the &ldquo;main&rdquo; method, all that happens is a few
configuration settings are overridden, and a server is started. That doesn&rsquo;t
tell the reader <em>anything</em> about what&rsquo;s happening.</p>

<p>Since I&rsquo;m using Scala, the new design makes the &ldquo;main&rdquo; function look more like
a Unix program:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">src1</span><span class="k">:</span> <span class="kt">DataSource</span><span class="o">[</span><span class="kt">Type1</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Type1Source</span><span class="o">()</span>
</span><span class='line'><span class="k">val</span> <span class="n">src2</span><span class="k">:</span> <span class="kt">DataSource</span><span class="o">[</span><span class="kt">Type2</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Type2Source</span><span class="o">()</span>
</span><span class='line'><span class="k">val</span> <span class="n">merger</span><span class="k">:</span> <span class="kt">Merger</span><span class="o">[</span><span class="kt">Type1</span>, <span class="kt">Type2</span>, <span class="kt">Type3</span><span class="o">]</span> <span class="k">=</span> <span class="nc">OneAndTwoMerger</span><span class="o">()</span>
</span><span class='line'><span class="k">val</span> <span class="n">output1</span><span class="k">:</span> <span class="kt">DataSink</span><span class="o">[</span><span class="kt">Type3</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Dest1Sink</span><span class="o">()</span>
</span><span class='line'><span class="k">val</span> <span class="n">output2</span><span class="k">:</span> <span class="kt">DataSink</span><span class="o">[</span><span class="kt">Type3</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Dest2Sink</span><span class="o">()</span>
</span><span class='line'>
</span><span class='line'><span class="nc">Merge</span><span class="o">(</span><span class="n">src1</span><span class="o">,</span> <span class="n">src2</span><span class="o">)</span> <span class="o">|</span> <span class="n">merger</span> <span class="n">tee</span> <span class="o">(</span><span class="n">output1</span><span class="o">,</span> <span class="n">output2</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// desugared to show there is no magic</span>
</span><span class='line'><span class="nc">Merge</span><span class="o">(</span><span class="n">src1</span><span class="o">,</span> <span class="n">src2</span><span class="o">).|(</span><span class="n">merger</span><span class="o">).</span><span class="n">tee</span><span class="o">(</span><span class="n">output1</span><span class="o">,</span> <span class="n">output2</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Ok, so data streams emanating from source-1 and source-2 are merged together
by a type-compatible &ldquo;merger&rdquo; class, who writes its output stream into both
output-1 and output-2.</p>

<p>There&rsquo;s not a lot of code required to create those interfaces and methods.
Basically any number of <code>DataSink[T]</code>s can be &ldquo;observers&rdquo; of a
<code>DataSource[T]</code>. Whenever a <code>DataSource</code> finds itself with data to publish, it
calls the <code>receiveMsgs(msgs: Seq[T])</code> method of all the observing <code>DataSink</code>s.
So now we have a &ldquo;reactive&rdquo; (sources produce data whenever it is available to
them), and typesafe pipeline where components can be swapped in an out.
Communication between sources and sinks by default is just function calls
(i.e. synchronous), but their calls could be wrapped with Futures or Akka
actors. Using function-calls makes coding, testing, debugging easier, has
better type-checking, and doesn&rsquo;t need backpressure. Increased asynchrony
would allow for higher speeds, but is not needed yet, and will be hooked-in
as-needed.</p>

<p>The biggest influences on this design are the Unix shell, and the Akka
Streaming library, which I saw some presentations about. I think both were
inspired by electrical engineering (e.g. circuits and signal processing).</p>

<p>With this approach, each component has a single responsibility: to ingest,
filter, transform, aggregate, or output streams of data. Then in the &ldquo;main&rdquo;
function we just assemble the data flow of the program by hooking components
together. This means to test the program, we just need to test that each
component produces or consumes the data that it says it does properly.</p>

<p>Before, almost all of my tests involved at least three separate major program
components. I think I will start by re-writing those, and wherever things
don&rsquo;t work, write lower-level tests of one thing, and keep zooming in like
that. That way, testing effort is spent on the parts that are hard to get
right. I&rsquo;m not writing the tests first because most of the code for the
program is simple hooking things into each other. Testing that would be an
unecessary duplication of effort. If the main logic is so plain to see and
understand and will not undergo heavy modification, it does not need to be
written twice. Then there are a few bits that use some pretty difficult
external APIs that can be used well and can be used badly. I want to make sure
that I&rsquo;m using those at least as well as is necessary for the program to
function properly. Most of the issues I&rsquo;ve had in the past are with the HDFS
API. With HDFS, it takes to take a little while sometimes for opens, writes,
and closes to propagate properly to all the replicas. Before I knew that, I
was using the API sub-optimally, and the program would crash every twelve
hours or so. That problem itself would not be simple to test against, but it
gives the impression that interaction ith these external APIs is where the
main complexity in my program lives.</p>

<p>In this new &ldquo;source-to-sink&rdquo; program model, a single Kafka &ldquo;topic&rdquo; can be
implemented as an <code>object</code> (i.e. Singleton) that has two ends (fields): a
<code>Producer</code> (which is a <code>DataSink[T]</code>, since it writes data out of the
program), and a corresponding <code>Consumer</code> (a <code>DataSource[T]</code> for the program).</p>

<p>So if the program has two &ldquo;main&rdquo; functions, one connects to the <code>Producer</code>
side of a Kafka topic, and the other connects to the <code>Consumer</code> side, all
using this Unix-like Scala DSL, then we have integrated Kafka as a resilient
buffer connecting two stages of the pipeline. This means the computation
subgraph connected within-JVM to the Consumer side can be taken offline for
fixing or augmentation without losing ephemeral data being collected by the
Producer side.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/05/12/name-according-to-function/">Name According to Function</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-05-12T15:08:16-07:00" pubdate data-updated="true">May 12<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Over the past few months, I wrote a kind of crappy program. Now I need to make
additions to that program and there are a lot of internals about the program
that I need to recall in order to be able to implement the additions
efficiently and robustly. This is not a world I want to continue to live in,
so my crappy program requires some sort of improvement. I looked to Amazon for
a book with the answers on &ldquo;what <em>specifically</em> to do&rdquo;. Based on its cover,
title, and reviews, I ended up with the book <strong>Clean Code: A Handbook of Agile
Software Craftsmanship</strong>, put together from multiple authors by a guy who
refers to himself as &ldquo;Uncle Bob&rdquo; (real name Robert C Martin). The book is
frankly a big part of the answer I was looking for.</p>

<p>I don&rsquo;t know a whole lot about Uncle Bob, but he seems to be <em>very</em>
experienced with designing, writing, maintaining, refactoring, etc. large Java
projects. He also is very well-read on modern software engineering, but for
the first quarter of the book, manages to stay away from the over-use of
terminology I&rsquo;m not familiar with. After that it goes into things like agile,
test driven development, behavior driven development, cohesion, object
oriented programming patterns (e.g. Gang of Four), plain old Java objects,
data access objects, etc. that I don&rsquo;t have much familiarity with. He also
talks about his conversations with (the only) guys in this arena that I have
heard of, including Fred Brooks and Martin Fowler.</p>

<p>His writing tone can be characterized as follows</p>

<ul>
<li>I have read and written sooo much more code than you</li>
<li>Over time, I have taken the time to think about the best way to make the
code &lsquo;clean&rsquo;</li>
<li>Herein, I shall share with you what I have learned</li>
<li>I&rsquo;ll use the best didactic methods I can think of</li>
<li>I hope you benefit as much as possible from my wisdom</li>
</ul>


<p>His main didactic method can be characterized as</p>

<ul>
<li>Here is an example of some bad code</li>
<li>This is how it goes wrong</li>
<li>This is why that is bad</li>
<li>Let&rsquo;s improve it in these areas</li>
<li>Here is the improved code</li>
<li>Note how this new code doesn&rsquo;t have the flaws of the previous</li>
</ul>


<p>So far I have read perhaps &frac12; of the book, and I have already come up with
and partially implemented a design for my problematic program that is <strong>so
much</strong> better than the old design, and a rough prototype implementation is
already running, and I have much more &ldquo;direction/vision&rdquo; for how it is going
to progress. That shows me that the <em>Clean Code</em> book has produced an
incredible return on investment.</p>

<p>The main thing I have understood from the book is that <strong>parts of programs
should do what they say they do</strong>. Put most briefly, there are two parts of
making that possible</p>

<ol>
<li><strong>Components should be simple enough to be described by just a few words</strong></li>
<li><strong>The <em>name</em> of a component should be the few words that describe it</strong></li>
</ol>


<p>It is embarrassing to say that I never thought of that myself, but the truth
is I didn&rsquo;t, and that is reflected all-too-obviously in the program that I
wrote. I can come up with countless excuses for why I wrote the program that
way, but that doesn&rsquo;t fix the problem. The only way to fix the problem is to
reorganize the program to conform to the above two rules.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/10/bigtable-paper-summary/">Bigtable Paper Summary</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-04-10T22:02:12-07:00" pubdate data-updated="true">Apr 10<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>When looking into what Cassandra and HBase are, and their relative strengths
and weaknesses, people often seem to think they can get away with the
following very succinct characterizations: &ldquo;Cassandra is like is Dynamo plus
Bigtable, and HBase is just Bigtable&rdquo;. I don&rsquo;t know much about Dynamo <em>or</em>
BigTable because we skipped those papers in my systems courses. So to get
started understanding what&rsquo;s going on with all this mess, I decided to read
the Bigtable paper. What follows is a brief summarization/retelling of the
<a href="http://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">Bigtable paper</a>. It follows roughly the form of the paper, especially in
that it starts high level, and then digs slightly lower-down into the
implementation. It contains basically only and all of the parts of the paper
that I found illuminating, but broken down into sentences that are hopefully
easier to understand.</p>

<h3>What problem are we solving?</h3>

<p>Bigtable provides an API for storing and retrieving data.</p>

<p>It is most useful if</p>

<ul>
<li>there is a <em>lot</em> of data coming in at a high rate over time</li>
<li>there is no need to join each data table with another</li>
<li>data might need to be updated</li>
<li>range queries are common</li>
</ul>


<p>Bigtable is a distributed database. It is a database management system which
allows you to define tables, write and update data, and run queries against
the stored data. It is similar to a relational database, except that it is not
&ldquo;relational&rdquo; in the sense denoted by the term &ldquo;relational database&rdquo;. Instead,
it brings its own type of data model, where instead of storing data in normal
two-dimensional table cells, you store it according to a new set of rules that
allows for flexibility in the shape of each record, while still enabling
overall efficiency.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/04/10/bigtable-paper-summary/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/09/what-is-a-rails-application/">What Is a Rails Application</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-04-09T14:47:14-07:00" pubdate data-updated="true">Apr 9<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>What is a server and how does it relate to my Rails app?</h1>

<p>I learned the basics of Ruby on Rails web application development a few years
ago. At that time, my understanding how that system works was as follows</p>

<ol>
<li>Find articles describing things Rails allows you to do easily</li>
<li>Decide on an app that requires only those things</li>
<li>Follow the instructions in those articles to implement your app idea</li>
<li>Push the app to Heroku</li>
<li>Now the app is accessible to anyone on the World Wide Web</li>
</ol>


<p>The fact that it is <em>so</em> easy to do such a thing is nothing short of magical.
Especially while you have <em>no idea</em> how any of it works. Now that I am
slightly more knowledgeable about how software systems are put together and
deployed, I&rsquo;d like to take a slightly more nuanced stab at what really was
going on when the above 5 steps were executed.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/04/09/what-is-a-rails-application/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/09/simple-first-deployment/">Simple First Deployment</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-04-09T13:45:39-07:00" pubdate data-updated="true">Apr 9<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I just had my first experience of &ldquo;deploying my system into production&rdquo;. I
have been learning about software engineering for a few years now, and I have
seen this term &ldquo;deploy into production&rdquo; many times, but never experienced it
myself. The &ldquo;software system&rdquo; that was deployed is an internal tool, almost 3
months in development by yours truly. This article is a retrospective of the
development of this system so far.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/04/09/simple-first-deployment/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/06/what-actually-is-ssh/">What Actually Is SSH</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-03-06T14:18:53-08:00" pubdate data-updated="true">Mar 6<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>SSH Tunneling</h3>

<p><em>&ldquo;Tunnelling&rdquo;, with two ells, is the British spelling.</em></p>

<p>A few months ago, I downloaded a tool (an ELK stack) that didn&rsquo;t work right
off the bat due to some sort of misconfiguration. It was running in a Vagrant-
made virtual machine (VM) on my laptop. The Vagrant setup script had forwarded
a local port on my laptop into the VM. So in order to debug it, my coworker
configured a chain of tunnels that enabled him to SSH into the VM on my
laptop.</p>

<p>In the back of my mind, I spent the next few weeks trying to figure out what
SSH port-forwarding is and how its syntax works, then another few weeks to
figure out what reverse port-forwarding is, and another few weeks to find
practical use-cases for each.</p>

<p>Here is my executive summary</p>

<pre><code>ssh -L [&lt;localhost&gt;:]&lt;localport&gt;:&lt;remotehost&gt;:&lt;remoteport&gt; &lt;gateway&gt;
</code></pre>

<p>By default, <code>&lt;localhost&gt;</code> will be <code>localhost</code>.</p>

<p>What this does is, start a serversocket listening to local address
<code>localhost:localport</code> using the &ldquo;SSH client&rdquo;. When a client establishes a
connection to that address, traffic received from that client will be
encrypted, and forwarded to the <code>sshd</code>[aemon] listening on port 22 of
<code>gateway</code>. (Only) after the gateway receives this traffic, the <code>sshd</code> will
establish a (normal, unencrypted) connection to remote address
<code>remotehost:remoteport</code>, and forward the data originally received by the SSH
client there. Response traffic originating from <code>remotehost:remoteport</code> will
go back to the <code>sshd</code>, back through the encrypted tunnel to the SSH client,
and back to the originating client.</p>

<p><em>Reverse</em> tunneling by contrast, means that traffic <em>originating</em> on the
remote end will be forwarded to the local end.</p>

<h2>What&rsquo;s SSH</h2>

<p>One thing that confused me about SSH forwarding, is that if I don&rsquo;t use some
extra flags to disable it, when I set up port forwarding to a another machine,
I also end up with a shell ready executing commands remotely. What is going on
here? It turns out it is doing what is called &ldquo;remote command execution&rdquo;.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/03/06/what-actually-is-ssh/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/10/09/on-learning/">On Learning</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/06/19/first-glance-at-genomics-with-adam-and-spark/">First Glance at Genomics With ADAM and Spark</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/05/30/hdfs-output-stream-api-semantics/">Hdfs Output Stream Api Semantics</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/05/14/ramblings-on-insight/">Ramblings on Insight</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/05/14/form-in-main-follows-program-function/">Form in &#8216;Main&#8217; Follows Program Function</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/ethanp">@ethanp</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'ethanp',
            count: 8,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Ethan Petuchowski -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
